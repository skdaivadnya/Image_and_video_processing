{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b884a81c-bc19-497a-9305-56ef0bc6929b",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8a2ae-d73f-4923-9b59-d5f89bc5c931",
   "metadata": {},
   "source": [
    "## In this notebook we are going to detect the face of an animal selected by the user which here is a CAT. We are going to use the the popular tool from openCV. We will be loading the dataset folder and iterating over images to detect the favorite animal. For this task we will be using cascade classifier. And the pretrained models to detect and predict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac69585-29e6-4051-bf5e-006e8bb9ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00990e6-01ed-4e38-af7c-54c4758f651e",
   "metadata": {},
   "source": [
    "## to detect the favorite pet from one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178612c-0790-4d78-85e3-e3e4346754cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bgr = cv.imread(\".jpg\",1)\n",
    "img_rgb = cv.cvtcolor(img_bgr, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463a2135-6611-4a37-94da-2f98b0c163f4",
   "metadata": {},
   "source": [
    "## to detect favorite pet from dataset which consists of multiple images ## to detect the images from a dataset folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3c94e0-2462-4713-916c-117b99e18b40",
   "metadata": {},
   "source": [
    "### to detect the images from a dataset folder\n",
    "### If all images are of the same format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22913661-1477-46dd-aed5-717ac210cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "images = [cv2.imread(file) for file in glob.glob('pet_images/*.jpg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df267b93-d424-4f0b-9754-7a934cef81c4",
   "metadata": {},
   "source": [
    "## For reading images of different formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6e3dd-f904-4179-99ed-605edd994776",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdir = 'path/to/files/'\n",
    "ext = ['png', 'jpg', 'gif']    # Add image formats here\n",
    "\n",
    "files = []\n",
    "[files.extend(glob.glob(imdir + '*.' + e)) for e in ext]\n",
    "\n",
    "images = [cv2.imread(file) for file in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ecf2b1-ce3c-4bea-871b-4c38a83255e9",
   "metadata": {},
   "source": [
    "## to utilise the cascadeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda247a0-cf53-4054-84b0-4e3e94a66511",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv.CascadeClassifier(\"XML files/haarcascade_frontalcatface.xml\")\n",
    "detectedFaces = faceCascade.detectMultiScale(img_rgb,1.1,4)\n",
    "print(detectedFaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30041fe-50f8-4a7e-8d10-dcc1b0c4119e",
   "metadata": {},
   "source": [
    "## Results of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da39f34-1bb9-46dc-8f0b-ad351e1606fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (length,breadth,width,height) in detectedFaces:\n",
    "    cv.rectangle(img_rgb,(length,breadth),(length+width, breadth+height),(255,0,0),10)\n",
    "\n",
    "plt.imshow(img_rgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
